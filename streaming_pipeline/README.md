## STREAMING PIPELINE
This pipeline is used to add the latest finance news and its embeddings on a vector DB so that the response generated by the LLM can be leveraged by the news using a RAG based approach.

This whole pipeline consists of the following steps,

- Listens for the latest finance news from Alpaca API in real-time using bytewax, 
- Fetches and the news, converts the news into embedding using huggingface sentence-transformers(all-MiniLM-L6-v2 is used).
- Inserts the embedding, news and metadata onto the QDRANT vector DB using Qdrant's python client.

## INSTRUCTIONS TO RUN LOCALLY

### 1. RUNNING IN STANDALONE MODE

1. Make sure python3 is installed.
2. Install all the dependencies using `pip install -r requirements.txt`
3. Login to [qdrant.io](www.qdrant.io) create a DB cluster and a API Key. Update the qdrant DB URL on the `src/constants.py` file. News will be inserted onto to the DB using this API key.
4. Login to [alpaca](https://app.alpaca.markets/) and create a API key and secret. We will be connecting with the Alpaca news using this API keys.
5. Setup the API KEYS as environment variables using export command.
    - `export QDRANT_API_KEY=<your-api-key>`
    - `export ALPACA_API_KEY=<your-api-key>`
    - `export ALPACA_API_SECRET=<your-api-key>`
6. Run `./run_batch.sh` to initiate the pipeline in batch mode. Modify the start, end dates accordingly in `run_batch.sh` file. Populate your Vector DB once using the news from past few months. Once DB is populated the streaming pipeline can be deployed to get and store latest news in real time using the `run_realtime_dev.sh` file.
7. Run `./run_realtime_dev.sh` to initiate the pipeline in real-time mode.


### 2. RUNNING IN A DOCKER CONTAINER

1. Make sure docker and docker-compose is installed.
2. RUN `docker build -t aakashveera/alpaca_stream:v1.0.0 .` to build the docker image.
3. RUN `docker-compose up -d` to start the docker container.


## PRODUCTION DEPLOYMENT

- The entire workflow is defined on `.github/workflows/` on the root of the directory. It gets triggered once a push is made onto github.

- The neccasay environment variables are set on github action secrets and will be used by the github runner for deployment.

- Once a push is made onto deploy branch, the runner checks the code, builds the docker image, logs on to AWS using the keys provided in secrets, pushes the build docker image onto AWS ECR(Elastic Container Registry).

- Once the image is pushed to ECR, second job gets triggered which runs inside a EC2 instance. It pulls the latest docker image from ECR and starts the container which continously fetches and adds the news embeddings into qdrant vector DB.